{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2022 Huawei Technologies Co., Ltd.\n",
    "# Licensed under CC BY-NC-SA 4.0 (Attribution-NonCommercial-ShareAlike 4.0 International) (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode\n",
    "#\n",
    "# The code is released for academic research use only. For commercial use, please contact Huawei Technologies Co., Ltd.\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "# This repository was forked from https://github.com/openai/guided-diffusion, which is under the MIT license\n",
    "\n",
    "\"\"\"\n",
    "Like image_sample.py, but use a noisy image classifier to guide the sampling\n",
    "process towards more realistic images.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import conf_mgt\n",
    "from utils import yamlread\n",
    "from guided_diffusion import dist_util\n",
    "\n",
    "# Workaround\n",
    "try:\n",
    "    import ctypes\n",
    "    libgcc_s = ctypes.CDLL('libgcc_s.so.1')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "from guided_diffusion.script_util import (\n",
    "    NUM_CLASSES,\n",
    "    model_and_diffusion_defaults,\n",
    "    classifier_defaults,\n",
    "    create_model_and_diffusion,\n",
    "    create_classifier,\n",
    "    select_args,\n",
    ")  # noqa: E402\n",
    "\n",
    "def toU8(sample):\n",
    "    if sample is None:\n",
    "        return sample\n",
    "\n",
    "    sample = ((sample + 1) * 127.5).clamp(0, 255).to(th.uint8)\n",
    "    sample = sample.permute(0, 2, 3, 1)\n",
    "    sample = sample.contiguous()\n",
    "    sample = sample.detach().cpu().numpy()\n",
    "    return sample\n",
    "\n",
    "\n",
    "def main(conf: conf_mgt.Default_Conf):\n",
    "\n",
    "    print(\"Start\", conf['name'])\n",
    "\n",
    "    device = dist_util.dev(conf.get('device'))\n",
    "\n",
    "\n",
    "    model, diffusion = create_model_and_diffusion(\n",
    "        **select_args(conf, model_and_diffusion_defaults().keys()), conf=conf\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        dist_util.load_state_dict(os.path.expanduser(\n",
    "            conf.model_path), map_location=\"cpu\")\n",
    "    )\n",
    "    model.to(device)\n",
    "    if conf.use_fp16:\n",
    "        model.convert_to_fp16()\n",
    "    model.eval()\n",
    "\n",
    "    show_progress = conf.show_progress\n",
    "\n",
    "    if conf.classifier_scale > 0 and conf.classifier_path:\n",
    "        print(\"loading classifier...\")\n",
    "        classifier = create_classifier(\n",
    "            **select_args(conf, classifier_defaults().keys()))\n",
    "        classifier.load_state_dict(\n",
    "            dist_util.load_state_dict(os.path.expanduser(\n",
    "                conf.classifier_path), map_location=\"cpu\")\n",
    "        )\n",
    "\n",
    "        classifier.to(device)\n",
    "        if conf.classifier_use_fp16:\n",
    "            classifier.convert_to_fp16()\n",
    "        classifier.eval()\n",
    "\n",
    "        def cond_fn(x, t, y=None, gt=None, **kwargs):\n",
    "            assert y is not None\n",
    "            with th.enable_grad():\n",
    "                x_in = x.detach().requires_grad_(True)\n",
    "                logits = classifier(x_in, t)\n",
    "                log_probs = F.log_softmax(logits, dim=-1)\n",
    "                selected = log_probs[range(len(logits)), y.view(-1)]\n",
    "                return th.autograd.grad(selected.sum(), x_in)[0] * conf.classifier_scale\n",
    "    else:\n",
    "        cond_fn = None\n",
    "\n",
    "    def model_fn(x, t, y=None, gt=None, **kwargs):\n",
    "        assert y is not None\n",
    "        return model(x, t, y if conf.class_cond else None, gt=gt)\n",
    "\n",
    "    print(\"sampling...\")\n",
    "    all_images = []\n",
    "\n",
    "    dset = 'eval'\n",
    "\n",
    "    eval_name = conf.get_default_eval_name()\n",
    "\n",
    "    dl = conf.get_dataloader(dset=dset, dsName=eval_name)\n",
    "\n",
    "    for batch in iter(dl):\n",
    "\n",
    "        for k in batch.keys():\n",
    "            if isinstance(batch[k], th.Tensor):\n",
    "                batch[k] = batch[k].to(device)\n",
    "\n",
    "        model_kwargs = {}\n",
    "\n",
    "        model_kwargs[\"gt\"] = batch['GT']\n",
    "\n",
    "        gt_keep_mask = batch.get('gt_keep_mask')\n",
    "        if gt_keep_mask is not None:\n",
    "            model_kwargs['gt_keep_mask'] = gt_keep_mask\n",
    "\n",
    "        batch_size = model_kwargs[\"gt\"].shape[0]\n",
    "\n",
    "        if conf.cond_y is not None:\n",
    "            classes = th.ones(batch_size, dtype=th.long, device=device)\n",
    "            model_kwargs[\"y\"] = classes * conf.cond_y\n",
    "        else:\n",
    "            classes = th.randint(\n",
    "                low=0, high=NUM_CLASSES, size=(batch_size,), device=device\n",
    "            )\n",
    "            model_kwargs[\"y\"] = classes\n",
    "\n",
    "        sample_fn = (\n",
    "            diffusion.p_sample_loop if not conf.use_ddim else diffusion.ddim_sample_loop\n",
    "        )\n",
    "\n",
    "\n",
    "        result = sample_fn(\n",
    "            model_fn,\n",
    "            (batch_size, 3, conf.image_size, conf.image_size),\n",
    "            clip_denoised=conf.clip_denoised,\n",
    "            model_kwargs=model_kwargs,\n",
    "            cond_fn=cond_fn,\n",
    "            device=device,\n",
    "            progress=show_progress,\n",
    "            return_all=True,\n",
    "            conf=conf\n",
    "        )\n",
    "        srs = toU8(result['sample'])\n",
    "        gts = toU8(result['gt'])\n",
    "        lrs = toU8(result.get('gt') * model_kwargs.get('gt_keep_mask') + (-1) *\n",
    "                   th.ones_like(result.get('gt')) * (1 - model_kwargs.get('gt_keep_mask')))\n",
    "\n",
    "        gt_keep_masks = toU8((model_kwargs.get('gt_keep_mask') * 2 - 1))\n",
    "\n",
    "        conf.eval_imswrite(\n",
    "            srs=srs, gts=gts, lrs=lrs, gt_keep_masks=gt_keep_masks,\n",
    "            img_names=batch['GT_name'], dset=dset, name=eval_name, verify_same=False)\n",
    "\n",
    "    print(\"sampling complete\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--conf_path', type=str, required=False, default=None)\n",
    "    args = vars(parser.parse_args())\n",
    "\n",
    "    conf_arg = conf_mgt.conf_base.Default_Conf()\n",
    "    conf_arg.update(yamlread(args.get('conf_path')))\n",
    "    main(conf_arg)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
